# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j0OPpaLmBPVDB55buf1JHE8GLz_nMemu
"""

import pandas as pd
import numpy as np
import urllib.request
import json
import time

from sklearn.model_selection import train_test_split

def extract_data_csv(file_name):
  df = pd.read_csv(file_name)

  return df

def get_train_test_data(df):
  label= pd.get_dummies(df.label).iloc[: , 1:]
  df= pd.concat([df,label],axis=1)
  df.drop('label', axis=1,inplace=True)
  
  train=df.iloc[:, 0:4].values
  test=df.iloc[: ,4:].values

  return(train, test)

def train_test_data():
  X, y = get_train_test_data(extract_data_csv("cpdata.csv"))

  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)

  return (X_train, X_test, y_train, y_test)

def normalizing_data(X_train, X_test):
  from sklearn.preprocessing import StandardScaler
  sc = StandardScaler()

  X_train = sc.fit_transform(X_train)
  X_test = sc.transform(X_test)

  return (X_train, X_test)

def clf_compute_metrics(clf):
  from sklearn.metrics import accuracy_score
  from sklearn.metrics import mean_squared_error

  X_train, X_test, y_train, y_test = train_test_data()
  X_train, X_test = normalizing_data(X_train, X_test)

  clf.fit(X_train, y_train)
  pred = clf.predict(X_test)

  acc = accuracy_score(y_test,pred)
  print("The accuracy of this model is: ", acc*100)

  mse = mean_squared_error(y_test, pred)
  print("The mean squared erro of this model is: ", mse)

from sklearn.tree import DecisionTreeClassifier
def feature_selection():
  from sklearn.ensemble import ExtraTreesRegressor
  import matplotlib.pyplot as plt

  X_train, X_test, y_train, y_test = train_test_data

  X_train, X_test = normalizing_data(X_train, X_test)
  X_train = pd.DataFrame(X_train, columns = ["temperature", "humidity", "ph", "rainfall"])

  reg= ExtraTreesRegressor()

  reg.fit(X_train,y_train)

  feat_importances = pd.Series(reg.feature_importances_, index=X_train.columns)
  feat_importances.nlargest(5).plot(kind='barh')
  plt.show()

def model_selection():
  from sklearn.tree import DecisionTreeRegressor
  from sklearn.tree import DecisionTreeClassifier

  return DecisionTreeClassifier()

def clf_model_validation(estimator):
  from sklearn.model_selection import GridSearchCV

  X_train, X_test, y_train, y_test = train_test_data()

  X_train, X_test = normalizing_data(X_train, X_test)

  parameters={"splitter":["best","random"],
            "max_depth" : [1,3,5,7,9,11,12],
           "min_samples_leaf":[1,2,3,4,5,6,7,8,9,10],
           "min_weight_fraction_leaf":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],
           "max_features":["auto","log2","sqrt",None],
           "max_leaf_nodes":[None,10,20,30,40,50,60,70,80,90] }

  gridsearch = GridSearchCV(estimator, param_grid=parameters, cv=5,
                         scoring='accuracy', verbose=1)

  gridsearch.fit(X_train, y_train)

  print(gridsearch.best_params_)

  return gridsearch.best_params_

#clf_model_validation(model_selection())

def clf_model_tuned(model):
  from sklearn.tree import DecisionTreeRegressor  
  from sklearn.tree import DecisionTreeClassifier 
  
  #max_depth=1, max_features='auto', max_leaf_nodes= None, min_samples_leaf=1, min_weight_fraction_leaf=0.1, splitter='best'
  #clf = DecisionTreeRegressor(max_depth= None, max_features='auto', max_leaf_nodes= None, min_samples_leaf=1, min_weight_fraction_leaf= 0.0, splitter='best')
  
  clf = DecisionTreeClassifier()

  return clf

clf_compute_metrics(clf_model_tuned(model_selection()))